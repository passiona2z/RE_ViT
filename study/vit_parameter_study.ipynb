{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=10, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 0.175, Val loss: 0.051, Val acc: 98.45 %\n",
      "Saving the best model with val acc: 98.45 %\n",
      "[Epoch 2] Train loss: 0.035, Val loss: 0.048, Val acc: 98.71 %\n",
      "Saving the best model with val acc: 98.71 %\n",
      "[Epoch 3] Train loss: 0.023, Val loss: 0.049, Val acc: 98.65 %\n",
      "[Epoch 4] Train loss: 0.016, Val loss: 0.050, Val acc: 98.68 %\n",
      "[Epoch 5] Train loss: 0.012, Val loss: 0.053, Val acc: 98.64 %\n",
      "[Epoch 6] Train loss: 0.009, Val loss: 0.053, Val acc: 98.69 %\n",
      "[Epoch 7] Train loss: 0.007, Val loss: 0.054, Val acc: 98.72 %\n",
      "Saving the best model with val acc: 98.72 %\n",
      "[Epoch 8] Train loss: 0.006, Val loss: 0.055, Val acc: 98.71 %\n",
      "[Epoch 9] Train loss: 0.006, Val loss: 0.055, Val acc: 98.72 %\n",
      "[Epoch 10] Train loss: 0.006, Val loss: 0.055, Val acc: 98.70 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#learning rate decay: cosine\n",
    "#optimizer: SGD momentum 0.9\n",
    "#batch_size: 32\n",
    "#weight decay: 0\n",
    "#grad clipping at global norm 1\n",
    "#dropout:0.1\n",
    "!python vit2_1.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opimizer 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=10, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 1.907, Val loss: 1.640, Val acc: 38.69 %\n",
      "Saving the best model with val acc: 38.69 %\n",
      "[Epoch 2] Train loss: 1.549, Val loss: 1.404, Val acc: 48.77 %\n",
      "Saving the best model with val acc: 48.77 %\n",
      "[Epoch 3] Train loss: 1.328, Val loss: 1.263, Val acc: 54.64 %\n",
      "Saving the best model with val acc: 54.64 %\n",
      "[Epoch 4] Train loss: 1.196, Val loss: 1.183, Val acc: 56.90 %\n",
      "Saving the best model with val acc: 56.90 %\n",
      "[Epoch 5] Train loss: 1.081, Val loss: 1.070, Val acc: 60.96 %\n",
      "Saving the best model with val acc: 60.96 %\n",
      "[Epoch 6] Train loss: 0.979, Val loss: 1.019, Val acc: 63.30 %\n",
      "Saving the best model with val acc: 63.30 %\n",
      "[Epoch 7] Train loss: 0.879, Val loss: 0.941, Val acc: 66.28 %\n",
      "Saving the best model with val acc: 66.28 %\n",
      "[Epoch 8] Train loss: 0.777, Val loss: 0.910, Val acc: 67.87 %\n",
      "Saving the best model with val acc: 67.87 %\n",
      "[Epoch 9] Train loss: 0.677, Val loss: 0.919, Val acc: 68.63 %\n",
      "Saving the best model with val acc: 68.63 %\n",
      "[Epoch 10] Train loss: 0.598, Val loss: 0.918, Val acc: 69.24 %\n",
      "Saving the best model with val acc: 69.24 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#learning rate decay: cosine\n",
    "#optimizer: Adam\n",
    "#batch_size: 32\n",
    "#weight decay: 0\n",
    "#grad clipping at global norm 1\n",
    "#dropout:0.1\n",
    "!python vit4.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam optimizer로 바꾸고 학습 시켰을 때 더 많은 epoches 가 걸린다. 따라서 학습을 20 epoches까지 더 진행했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=1, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 1.000, Val loss: 1.087, Val acc: 60.97 %\n",
      "Saving the best model with val acc: 60.97 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python vit4_1.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=4, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 1.001, Val loss: 1.053, Val acc: 62.08 %\n",
      "Saving the best model with val acc: 62.08 %\n",
      "[Epoch 2] Train loss: 0.939, Val loss: 0.973, Val acc: 64.76 %\n",
      "Saving the best model with val acc: 64.76 %\n",
      "[Epoch 3] Train loss: 0.793, Val loss: 0.897, Val acc: 67.88 %\n",
      "Saving the best model with val acc: 67.88 %\n",
      "[Epoch 4] Train loss: 0.631, Val loss: 0.846, Val acc: 70.29 %\n",
      "Saving the best model with val acc: 70.29 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python vit4_1.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=20, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 0.997, Val loss: 1.109, Val acc: 60.89 %\n",
      "Saving the best model with val acc: 60.89 %\n",
      "[Epoch 2] Train loss: 0.965, Val loss: 1.141, Val acc: 60.04 %\n",
      "[Epoch 3] Train loss: 0.920, Val loss: 0.966, Val acc: 65.27 %\n",
      "Saving the best model with val acc: 65.27 %\n",
      "[Epoch 4] Train loss: 0.878, Val loss: 0.969, Val acc: 65.00 %\n",
      "[Epoch 5] Train loss: 0.835, Val loss: 0.932, Val acc: 66.35 %\n",
      "Saving the best model with val acc: 66.35 %\n",
      "[Epoch 6] Train loss: 0.785, Val loss: 0.927, Val acc: 67.14 %\n",
      "Saving the best model with val acc: 67.14 %\n",
      "[Epoch 7] Train loss: 0.738, Val loss: 0.870, Val acc: 69.74 %\n",
      "Saving the best model with val acc: 69.74 %\n",
      "[Epoch 8] Train loss: 0.685, Val loss: 0.869, Val acc: 70.01 %\n",
      "Saving the best model with val acc: 70.01 %\n",
      "[Epoch 9] Train loss: 0.628, Val loss: 0.837, Val acc: 70.70 %\n",
      "Saving the best model with val acc: 70.70 %\n",
      "[Epoch 10] Train loss: 0.564, Val loss: 0.878, Val acc: 70.01 %\n",
      "[Epoch 11] Train loss: 0.498, Val loss: 0.864, Val acc: 71.18 %\n",
      "Saving the best model with val acc: 71.18 %\n",
      "[Epoch 12] Train loss: 0.426, Val loss: 0.964, Val acc: 70.70 %\n",
      "[Epoch 13] Train loss: 0.347, Val loss: 0.962, Val acc: 71.80 %\n",
      "Saving the best model with val acc: 71.80 %\n",
      "[Epoch 14] Train loss: 0.268, Val loss: 1.095, Val acc: 72.29 %\n",
      "Saving the best model with val acc: 72.29 %\n",
      "[Epoch 15] Train loss: 0.193, Val loss: 1.226, Val acc: 71.56 %\n",
      "[Epoch 16] Train loss: 0.127, Val loss: 1.471, Val acc: 71.90 %\n",
      "[Epoch 17] Train loss: 0.076, Val loss: 1.732, Val acc: 71.77 %\n",
      "[Epoch 18] Train loss: 0.037, Val loss: 2.017, Val acc: 71.75 %\n",
      "[Epoch 19] Train loss: 0.016, Val loss: 2.292, Val acc: 71.55 %\n",
      "[Epoch 20] Train loss: 0.008, Val loss: 2.377, Val acc: 71.49 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "!python vit4_1.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate sceduling을 변경하면서 학습을 진행했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=10, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 0.175, Val loss: 0.050, Val acc: 98.54 %\n",
      "Saving the best model with val acc: 98.54 %\n",
      "[Epoch 2] Train loss: 0.035, Val loss: 0.048, Val acc: 98.61 %\n",
      "Saving the best model with val acc: 98.61 %\n",
      "[Epoch 3] Train loss: 0.025, Val loss: 0.048, Val acc: 98.67 %\n",
      "Saving the best model with val acc: 98.67 %\n",
      "[Epoch 4] Train loss: 0.018, Val loss: 0.049, Val acc: 98.67 %\n",
      "[Epoch 5] Train loss: 0.014, Val loss: 0.051, Val acc: 98.62 %\n",
      "[Epoch 6] Train loss: 0.011, Val loss: 0.052, Val acc: 98.65 %\n",
      "[Epoch 7] Train loss: 0.010, Val loss: 0.053, Val acc: 98.67 %\n",
      "[Epoch 8] Train loss: 0.008, Val loss: 0.054, Val acc: 98.66 %\n",
      "[Epoch 9] Train loss: 0.008, Val loss: 0.054, Val acc: 98.65 %\n",
      "[Epoch 10] Train loss: 0.007, Val loss: 0.054, Val acc: 98.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#learning rate decay: linear\n",
    "#optimizer: SGD momentum 0.9\n",
    "#batch_size: 32\n",
    "#weight decay: 0\n",
    "#grad clipping at global norm 1\n",
    "#dropout:0.1\n",
    "!python vit5.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=10, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 0.175, Val loss: 0.051, Val acc: 98.45 %\n",
      "Saving the best model with val acc: 98.45 %\n",
      "[Epoch 2] Train loss: 0.035, Val loss: 0.049, Val acc: 98.54 %\n",
      "Saving the best model with val acc: 98.54 %\n",
      "[Epoch 3] Train loss: 0.024, Val loss: 0.048, Val acc: 98.63 %\n",
      "Saving the best model with val acc: 98.63 %\n",
      "[Epoch 4] Train loss: 0.017, Val loss: 0.050, Val acc: 98.69 %\n",
      "Saving the best model with val acc: 98.69 %\n",
      "[Epoch 5] Train loss: 0.013, Val loss: 0.051, Val acc: 98.68 %\n",
      "[Epoch 6] Train loss: 0.010, Val loss: 0.053, Val acc: 98.69 %\n",
      "[Epoch 7] Train loss: 0.008, Val loss: 0.055, Val acc: 98.72 %\n",
      "Saving the best model with val acc: 98.72 %\n",
      "[Epoch 8] Train loss: 0.006, Val loss: 0.056, Val acc: 98.69 %\n",
      "[Epoch 9] Train loss: 0.005, Val loss: 0.057, Val acc: 98.69 %\n",
      "[Epoch 10] Train loss: 0.004, Val loss: 0.057, Val acc: 98.70 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#learning rate decay: exponential (gamma = 0.9)\n",
    "#optimizer: SGD momentum 0.9\n",
    "#batch_size: 32\n",
    "#weight decay: 0\n",
    "#grad clipping at global norm 1\n",
    "#dropout:0.1\n",
    "!python vit6.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dropout_rate=0.1, epochs=10, img_size=224, lr=0.001, mode='train', num_classes=10, pretrained=1, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1] Train loss: 0.175, Val loss: 0.051, Val acc: 98.58 %\n",
      "Saving the best model with val acc: 98.58 %\n",
      "[Epoch 2] Train loss: 0.035, Val loss: 0.048, Val acc: 98.62 %\n",
      "Saving the best model with val acc: 98.62 %\n",
      "[Epoch 3] Train loss: 0.023, Val loss: 0.048, Val acc: 98.73 %\n",
      "Saving the best model with val acc: 98.73 %\n",
      "[Epoch 4] Train loss: 0.016, Val loss: 0.050, Val acc: 98.65 %\n",
      "[Epoch 5] Train loss: 0.010, Val loss: 0.053, Val acc: 98.75 %\n",
      "Saving the best model with val acc: 98.75 %\n",
      "[Epoch 6] Train loss: 0.007, Val loss: 0.054, Val acc: 98.67 %\n",
      "[Epoch 7] Train loss: 0.006, Val loss: 0.056, Val acc: 98.66 %\n",
      "[Epoch 8] Train loss: 0.005, Val loss: 0.057, Val acc: 98.68 %\n",
      "[Epoch 9] Train loss: 0.004, Val loss: 0.058, Val acc: 98.65 %\n",
      "[Epoch 10] Train loss: 0.004, Val loss: 0.058, Val acc: 98.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\jewoo\\anaconda3\\envs\\dtqn\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "#learning rate decay: ReduceLROnPlateau factor = 0.5 patient 1(validation 향상이 없을 경우 RL을 epoch 마다 반으로 줄임)\n",
    "#optimizer: SGD momentum 0.9\n",
    "#batch_size: 32\n",
    "#weight decay: 0\n",
    "#grad clipping at global norm 1\n",
    "#dropout:0.1\n",
    "!python vit7.py --pretrained 1  --batch_size 32 --weight_decay 0 --clip_value 1 --dropout_rate 0.1 --epochs 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image size를 224x224로 positional embedding을 더하지 않고 학습을 시켰는데 결과가 좋지 않다. vit_ablation.ipynb에서 추가 결과 확인바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dataname='cifar10', drop_rate=0.1, epochs=20, img_size=224, latent_vec_dim=128, lr=0.001, mode='train', num_classes=10, num_heads=8, num_layers=12, patch_size=16, pretrained=0, save_acc=10, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[0] train loss: 2.014, validation loss: 1.901, validation acc 30.18 %\n",
      "[1] train loss: 1.913, validation loss: 1.863, validation acc 30.54 %\n",
      "[2] train loss: 1.857, validation loss: 1.798, validation acc 33.66 %\n",
      "[3] train loss: 1.800, validation loss: 1.784, validation acc 34.90 %\n",
      "[4] train loss: 1.747, validation loss: 1.749, validation acc 35.24 %\n",
      "[5] train loss: 1.714, validation loss: 1.701, validation acc 37.30 %\n",
      "[6] train loss: 1.684, validation loss: 1.645, validation acc 40.00 %\n",
      "[7] train loss: 1.676, validation loss: 1.662, validation acc 39.06 %\n",
      "[8] train loss: 1.653, validation loss: 1.625, validation acc 40.52 %\n",
      "[9] train loss: 1.644, validation loss: 1.612, validation acc 41.30 %\n",
      "[10] train loss: 1.638, validation loss: 1.637, validation acc 40.66 %\n",
      "[11] train loss: 1.627, validation loss: 1.625, validation acc 40.10 %\n",
      "[12] train loss: 1.622, validation loss: 1.625, validation acc 40.46 %\n",
      "[13] train loss: 1.599, validation loss: 1.611, validation acc 41.00 %\n",
      "[14] train loss: 1.582, validation loss: 1.605, validation acc 41.32 %\n",
      "[15] train loss: 1.589, validation loss: 1.624, validation acc 40.38 %\n",
      "[16] train loss: 1.570, validation loss: 1.605, validation acc 41.56 %\n",
      "[17] train loss: 1.563, validation loss: 1.565, validation acc 42.38 %\n",
      "[18] train loss: 1.562, validation loss: 1.577, validation acc 42.54 %\n",
      "[19] train loss: 1.551, validation loss: 1.546, validation acc 43.32 %\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10\n",
    "!python vit_no_pos_embedding.py --pretrained 0 --batch_size 32 --weight_decay 0 --clip_value 1 --drop_rate 0.1 --epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, clip_value=1.0, dataname='cifar10', drop_rate=0.1, epochs=20, img_size=224, latent_vec_dim=128, lr=0.001, mode='train', num_classes=10, num_heads=8, num_layers=12, patch_size=16, pretrained=0, save_acc=10, weight_decay=0.0)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[0] train loss: 2.086, validation loss: 1.992, validation acc 25.88 %\n",
      "[1] train loss: 2.000, validation loss: 1.949, validation acc 27.26 %\n",
      "[2] train loss: 1.963, validation loss: 1.928, validation acc 29.60 %\n",
      "[3] train loss: 1.947, validation loss: 1.912, validation acc 29.38 %\n",
      "[4] train loss: 1.924, validation loss: 1.890, validation acc 30.00 %\n",
      "[5] train loss: 1.911, validation loss: 1.877, validation acc 31.02 %\n",
      "[6] train loss: 1.902, validation loss: 1.873, validation acc 31.46 %\n",
      "[7] train loss: 1.869, validation loss: 1.849, validation acc 32.26 %\n",
      "[8] train loss: 1.861, validation loss: 1.820, validation acc 33.30 %\n",
      "[9] train loss: 1.832, validation loss: 1.793, validation acc 33.44 %\n",
      "[10] train loss: 1.812, validation loss: 1.788, validation acc 34.50 %\n",
      "[11] train loss: 1.795, validation loss: 1.765, validation acc 35.28 %\n",
      "[12] train loss: 1.779, validation loss: 1.813, validation acc 34.04 %\n",
      "[13] train loss: 1.762, validation loss: 1.756, validation acc 36.00 %\n",
      "[14] train loss: 1.752, validation loss: 1.739, validation acc 36.30 %\n",
      "[15] train loss: 1.744, validation loss: 1.786, validation acc 34.68 %\n",
      "[16] train loss: 1.733, validation loss: 1.710, validation acc 38.22 %\n",
      "[17] train loss: 1.718, validation loss: 1.702, validation acc 37.14 %\n",
      "[18] train loss: 1.709, validation loss: 1.694, validation acc 37.90 %\n",
      "[19] train loss: 1.697, validation loss: 1.648, validation acc 39.52 %\n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10\n",
    "!python vit_with_pos_embedding.py --pretrained 0 --batch_size 32 --weight_decay 0 --clip_value 1 --drop_rate 0.1 --epochs 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtqn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
